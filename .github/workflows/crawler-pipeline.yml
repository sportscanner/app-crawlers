name: Run Crawler Pipeline

on:
  schedule:
    - cron: '*/30 * * * *'  # This will run the workflow every hour on the hour
  workflow_dispatch:  # Allows you to manually trigger the workflow if needed

jobs:
  backup-and-store-historical:
    name: "Backup current datasets"
    runs-on: ubuntu-latest
    steps:
      - name: Fetch/Dump postgres data
        run: |
          OUTPUT_FILE=/tmp/sportscanner_$(date +'%Y%m%d_%H%M%S').json
          echo "Dumping outputs as: ${OUTPUT_FILE} from postgres DB"
          psql "${{ secrets.POSTGRES_CONNECTION_STRING }}" -c "COPY (SELECT row_to_json(t) FROM sportscanner t) TO STDOUT;" > $OUTPUT_FILE

      - name: Install Filen CLI
        run: |
          wget -q https://github.com/FilenCloudDienste/filen-cli/releases/download/v0.0.29/filen-cli-v0.0.29-linux-x64 -O filen
          chmod +x filen

      - name: Upload data dump to cloud storage
        run: |
          OUTPUT_FILE=$(ls /tmp/sportscanner_*.json)
          echo "Uploading outputs from: ${OUTPUT_FILE} to cloud storage"
          ./filen --email "${{ secrets.FILEN_EMAIL }}" --password "${{ secrets.FILEN_PASSWORD }}" upload $OUTPUT_FILE datasets/

  run-crawler-pipeline:
    runs-on: ubuntu-latest
    needs: backup-and-store-historical
    name: "Fetch latest data"
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker and log in to GitHub Container Registry
        run: |
          echo ${{ secrets.GHCR }} | docker login ghcr.io -u yasir-khalid --password-stdin

      - name: Write Firebase JSON secret to file
        run: |
          echo "${{ secrets.FIREBASE_ADMIN_SDK_JSON }}" > /tmp/sportscanner-firebase-adminsdk.json

      - name: Create .env file from secret
        run: |
          echo "${{ secrets.ENV_FILE_CONTENT }}" > .env  # Store the content of your .env file in the secret "ENV_FILE_CONTENT"

      - name: Run crawler pipeline container
        run: |
          echo "Running container for image (tag: latest) to run data crawlers pipeline"
          docker run --rm --platform=linux/amd64 --network=host --env-file .env \
            -v /tmp/sportscanner-firebase-adminsdk.json:/app/sportscanner-21f2f-firebase-adminsdk-g391o-7562082fdb.json \
            ghcr.io/sportscanner/app-crawlers:latest \
            python sportscanner/crawlers/pipeline.py
